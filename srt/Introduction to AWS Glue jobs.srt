1
00:00:00,100 --> 00:00:03,930
Introduction to AWS Glue Jobs.

2
00:00:03,930 --> 00:00:05,800
A job in AWS Glue

3
00:00:06,240 --> 00:00:07,940
consists of the business logic

4
00:00:08,140 --> 00:00:12,480
that performs extract, transform, and load, or ETL work.

5
00:00:13,430 --> 00:00:16,980
An AWS Glue job is composed of data sources,

6
00:00:17,080 --> 00:00:20,340
a transformation script, and data targets.

7
00:00:21,530 --> 00:00:25,160
You can define triggers to initiate jobs based on a schedule,

8
00:00:25,620 --> 00:00:27,430
an event, or on demand.

9
00:00:29,260 --> 00:00:33,900
You can visually create and run your job by using AWS Glue Studio,

10
00:00:34,060 --> 00:00:37,040
a streamlined graphical interface in AWS Glue.

11
00:00:38,030 --> 00:00:42,000
You can also monitor job runs to understand runtime metrics

12
00:00:42,500 --> 00:00:46,600
such as completion status, duration, and start time.

13
00:00:47,630 --> 00:00:52,720
With AWS Glue, you only pay for the time your ETL job takes to run.

14
00:00:54,600 --> 00:00:56,580
Here are the key components of a job.

15
00:00:57,460 --> 00:01:03,420
A data source is a datastore that is used as input to a process or transform.

16
00:01:04,430 --> 00:01:10,120
Some data source options include AWS Glue data catalog, Amazon S3 buckets,

17
00:01:10,600 --> 00:01:15,420
Amazon Kinesis, Amazon DynamoDB, and relational databases.

18
00:01:16,700 --> 00:01:22,000
A transformation script is the code that extracts data from your data source,

19
00:01:22,480 --> 00:01:25,820
transforms the data, and loads it into your data targets.

20
00:01:26,530 --> 00:01:31,460
AWS Glue can automatically generate PySpark or Scala scripts for you,

21
00:01:31,780 --> 00:01:33,220
or you can use your own.

22
00:01:34,630 --> 00:01:38,660
A data target is where the job writes the transformed data.

23
00:01:39,360 --> 00:01:43,600
Some data target options include the AWS Glue data catalog,

24
00:01:43,820 --> 00:01:46,480
Amazon S3 buckets, and Amazon Redshift.

25
00:01:49,530 --> 00:01:52,960
Now let's look at an AWS Glue job example.

26
00:01:53,700 --> 00:01:57,930
You can run an AWS Glue job using a built-in transformation,

27
00:01:57,930 --> 00:02:00,240
the relationalized transform in this case,

28
00:02:00,320 --> 00:02:03,640
to convert semi-structured data into relational tables.

29
00:02:04,730 --> 00:02:07,300
For example, this semi-structured data

30
00:02:07,680 --> 00:02:11,860
contains a single value, A, a pair of values, B1 and B2,

31
00:02:12,230 --> 00:02:15,460
a structure C with children X and Y, and an array, D[ ].

32
00:02:16,460 --> 00:02:18,840
After running the AWS Glue job,

33
00:02:19,060 --> 00:02:22,720
the value A converts directly to a column in a relational table,

34
00:02:23,360 --> 00:02:26,640
B1 and B2 convert to relational columns.

35
00:02:27,530 --> 00:02:31,640
Structure C converts to two separate columns with each child value,

36
00:02:31,900 --> 00:02:34,580
C dot X and C dot Y, in each column.

37
00:02:35,320 --> 00:02:39,930
Array D[ ] converts to a relational column with a foreign key, or FK,

38
00:02:39,930 --> 00:02:41,940
that points to another relational table.

39
00:02:43,280 --> 00:02:47,740
Along with a primary key, or PK, the second relational table has columns

40
00:02:47,800 --> 00:02:50,840
contain the offset and value of the items in the array.

41
00:02:52,166 --> 00:02:58,160
AWS Glue can then output this converted data directly to a relational database.

42
00:02:58,160 --> 00:03:01,900
Order files in Amazon S3 for further analysis with tools

43
00:03:01,960 --> 00:03:05,190
such as Amazon Athena and Amazon Redshift Spectrum.

